{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f123a781-7610-48ef-a6e7-47ad4e85d348",
   "metadata": {},
   "source": [
    "# PsychoPy output .csv preprocessing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c435c9-8a3f-43b5-a095-16d5c06570ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T18:22:00.593528Z",
     "start_time": "2024-02-03T18:22:00.508949Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1b352c-4109-4fb5-bbd6-f79b1d2b4307",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T18:22:01.054986Z",
     "start_time": "2024-02-03T18:22:01.027593Z"
    }
   },
   "outputs": [],
   "source": [
    "def chunk_list(input_list, chunk_size):\n",
    "    \"\"\"Splits the list into chunks of specified size.\"\"\"\n",
    "    return [input_list[i:i + chunk_size] for i in range(0, len(input_list), chunk_size)]\n",
    "\n",
    "def accuracy_with_order(user_responses, correct_answers):\n",
    "    accuracies = []\n",
    "    for user_resp, correct_ans in zip(user_responses, correct_answers):\n",
    "        correct_count = sum(u == c for u, c in zip(user_resp, correct_ans))\n",
    "        accuracy = correct_count / len(correct_ans)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies\n",
    "\n",
    "def accuracy_without_order(user_responses, correct_answers):\n",
    "    accuracies = []\n",
    "    for user_resp, correct_ans in zip(user_responses, correct_answers):\n",
    "        correct_count = sum(user_resp.count(c) for c in set(correct_ans))\n",
    "        accuracy = correct_count / len(correct_ans)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies\n",
    "\n",
    "def convert_to_floats(str_list):\n",
    "    float_list = []\n",
    "    for s in str_list:\n",
    "        # Use ast.literal_eval to safely evaluate the string as a list\n",
    "        # Then convert each element in the resulting list to a float\n",
    "        floats = ast.literal_eval(s)\n",
    "        float_list.extend(floats if isinstance(floats, list) else [floats])\n",
    "    return float_list\n",
    "\n",
    "# Updated function that extracts only the first float from each string\n",
    "def convert_to_floats(str_list):\n",
    "    float_list = []\n",
    "    for s in str_list:\n",
    "        # Use ast.literal_eval to safely evaluate the string as a list\n",
    "        # Then convert each element in the resulting list to a float\n",
    "        floats = ast.literal_eval(s)\n",
    "        float_list.extend(floats if isinstance(floats, list) else [floats])\n",
    "    return float_list\n",
    "\n",
    "def convert_strings_to_float_lists(str_list):\n",
    "    float_lists = []\n",
    "    for s in str_list:\n",
    "        if s == \"None\": \n",
    "            float_lists.append(s)\n",
    "        else:\n",
    "        # Convert the string representation of list to actual list and then to floats\n",
    "            float_list = [float(x) for x in ast.literal_eval(s)]\n",
    "            float_lists.append(float_list)\n",
    "    return float_lists\n",
    "\n",
    "def chunk_list(lst, n):\n",
    "        chunked_list = []\n",
    "        for i in range(0, len(lst), n):\n",
    "            chunked_list.append(lst[i:i + n])\n",
    "        return chunked_list\n",
    "\n",
    "def has_common_letter(pair1, pair2):\n",
    "        return any(letter in pair2 for letter in pair1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed4aa4-b9fc-4d5d-82f3-ba028f5b9fdb",
   "metadata": {},
   "source": [
    "# Dual WM-Flanker analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a20a34-9385-4f7f-97a5-fec7f35fef92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T18:22:07.678955Z",
     "start_time": "2024-02-03T18:22:02.239719Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "n_blocks = 12\n",
    "n_supertrials = 6\n",
    "n_flanker = 8\n",
    "subsets = []\n",
    "path = \"/Users/fzaki001/Documents/AHC5-rooms/WME/wme/data/\"\n",
    "subjects = sorted([i[8:10] for i in os.listdir(path) if i.endswith(\"csv\")])\n",
    "wme_dict = dict({\n",
    "    \"sub\": [],\n",
    "    \"acc_fl\": [],\n",
    "    \"acc_norder\": [],\n",
    "    \"4-1_fl_error_wm_acc_norder\": [],\n",
    "    \"5-1_fl_error_wm_acc_norder\": [],\n",
    "    \"4-0_fl_error_wm_acc_norder\": [],\n",
    "    \"5-0_fl_error_wm_acc_norder\": [],\n",
    "    \"4-many_fl_error_wm_acc_norder\": [],\n",
    "    \"5-many_fl_error_wm_acc_norder\": [],\n",
    "    \"4-acc_fl\": [],\n",
    "    \"5-acc_fl\": [],\n",
    "    \"4-acc_con\": [],\n",
    "    \"5-acc_con\": [],\n",
    "    \"4-acc_incon\": [],\n",
    "    \"5-acc_incon\": [],\n",
    "    \"1_fl_error_trials\": [],\n",
    "    \n",
    "    \"4-rt_con_corr\": [],\n",
    "    \"5-rt_con_corr\": [],\n",
    "    \"4-rt_incon_corr\": [],\n",
    "    \"5-rt_incon_corr\": [],\n",
    "    \"4-rt_con_incorr\": [],\n",
    "    \"5-rt_con_incorr\": [],\n",
    "    \"4-rt_incon_incorr\": [],\n",
    "    \"5-rt_incon_incorr\": [],\n",
    "    \n",
    "    \"4-good_rt_con_corr\": [],\n",
    "    \"5-good_rt_con_corr\": [],\n",
    "    \"4-good_rt_incon_corr\": [],\n",
    "    \"5-good_rt_incon_corr\": [],\n",
    "    \"4-good_rt_con_incorr\": [],\n",
    "    \"5-good_rt_con_incorr\": [],\n",
    "    \"4-good_rt_incon_incorr\": [],\n",
    "    \"5-good_rt_incon_incorr\": [],\n",
    "    #\"pes\": [],\n",
    "    \"4-acc_order\": [],\n",
    "    \"5-acc_order\": [],\n",
    "    \"4-acc_norder\": [],\n",
    "    \"5-acc_norder\": [],\n",
    "    \n",
    "    \"wm_err0_fl_err0\": [],\n",
    "    \"wm_err0_fl_err1\": [],\n",
    "    \"wm_err1_fl_err0\": [],\n",
    "    \"wm_err1_fl_err1\": [],\n",
    "    \n",
    "    \"chi2\": [],\n",
    "    \"diff_con\": [],\n",
    "    \"diff_incon\": [],\n",
    "    \n",
    "    \"4-mean_letters_from_fl_err\": [],\n",
    "    \"5-mean_letters_from_fl_err\": [],\n",
    "    \"4-mean_letters_from_fl_corr\": [],\n",
    "    \"5-mean_letters_from_fl_corr\": [],\n",
    "    \n",
    "    \"cnt_mean\": [],\n",
    "    \"cnt_n\": [],\n",
    "    \"hand\": [],\n",
    "    \"repeat\": [],\n",
    "    \"repeat_cnt\": [],\n",
    "    \"not_repeat_cnt\": [],\n",
    "    \n",
    "    \"ratio_incon_correct\": [],\n",
    "    \"4-ratio_incon_correct\": [],\n",
    "    \"5-ratio_incon_correct\": [],\n",
    "    \"ratio_post_incon_correct\": [],\n",
    "    \"4-ratio_post_incon_correct\": [],\n",
    "    \"5-ratio_post_incon_correct\": [],\n",
    "    \"ratio_incon_error\": [],\n",
    "    \"4-ratio_incon_error\": [],\n",
    "    \"5-ratio_incon_error\": [],\n",
    "    \"ratio_post_incon_error\": [],\n",
    "    \"4-ratio_post_incon_error\": [],\n",
    "    \"5-ratio_post_incon_error\": [],\n",
    "    \n",
    "    \"R_ratio_incon_correct\": [],\n",
    "    \"L_ratio_incon_correct\": [],\n",
    "    \"R_ratio_post_incon_correct\": [],\n",
    "    \"L_ratio_post_incon_correct\": [],\n",
    "    \"R_ratio_incon_error\": [],\n",
    "    \"L_ratio_incon_error\": [],\n",
    "    \"R_ratio_post_incon_error\": [],\n",
    "    \"L_ratio_post_incon_error\": [],\n",
    "                \n",
    "    \"ratio_con\": [],\n",
    "    \"ratio_incon\": [],\n",
    "    \"ratio_post_con\": [],\n",
    "    \"ratio_post_incon\": [],\n",
    "    \"ratio_post_error_con\": [],\n",
    "    \"ratio_post_error_incon\": [],\n",
    "\n",
    "    \"L_ratio_con\": [],\n",
    "    \"R_ratio_con\": [],\n",
    "    \"L_ratio_incon\": [],\n",
    "    \"R_ratio_incon\": [],\n",
    "    \"L_ratio_post_con\": [],\n",
    "    \"R_ratio_post_con\": [],\n",
    "    \"L_ratio_post_incon\": [],\n",
    "    \"R_ratio_post_incon\": [],\n",
    "    \"L_ratio_post_error_con\": [],\n",
    "    \"R_ratio_post_error_con\": [],\n",
    "    \"L_ratio_post_error_incon\": [],\n",
    "    \"R_ratio_post_error_incon\": [],\n",
    "\n",
    "})\n",
    "\n",
    "for sub in subjects:\n",
    "    data = pd.read_csv(\"{}sub-2800{}_wme-eeg_s1_r1_e1.csv\".format(path, sub))\n",
    "    counterbalance = (data[\"hand\"][0], data[\"repeat\"][0])\n",
    "    row_start = list(data[\"conditionText\"]).index(4)\n",
    "    first_five_columns = data.iloc[row_start:, :5]\n",
    "    columns_from_start = data.iloc[row_start:, list(data.columns).index(\"wm_ISI\"):list(data.columns).index(\"supertrial_blockAcc_wm\")+1]\n",
    "    data = pd.concat([first_five_columns, columns_from_start], axis=1)\n",
    "    print(\"Loading subject {}\".format(sub))\n",
    "    print(\"\")\n",
    "\n",
    "    shown_letters = data[\"shown_letters\"].dropna().reset_index(drop=True)\n",
    "    shown_letters = [i for i in shown_letters if len(i)>=4]\n",
    "    for i in range(len(shown_letters)-1):\n",
    "        if shown_letters[i][:4] == shown_letters[i+1][:4]:\n",
    "            shown_letters[i] = shown_letters[i]+\"*\"\n",
    "    shown_letters = [i for i in shown_letters if i[-1] != \"*\"]\n",
    "    assert len(shown_letters) == (n_blocks * n_supertrials), \"Check your data length!\"\n",
    "    \n",
    "    wm_response = data[\"wm_response\"].dropna().reset_index(drop=True)\n",
    "    assert len(wm_response) == (n_blocks * n_supertrials), \"Check your data length!\"\n",
    "    \n",
    "    acc_order = accuracy_with_order(wm_response, [i.upper() for i in shown_letters])\n",
    "    assert len(acc_order) == n_blocks * n_supertrials, \"Check your data length!\"\n",
    "    \n",
    "    acc_norder = accuracy_without_order(wm_response, [i.upper() for i in shown_letters])\n",
    "    assert len(acc_norder) == n_blocks * n_supertrials, \"Check your data length!\"\n",
    "    \n",
    "    acc_fl = data[\"fl_accuracy\"].dropna().reset_index(drop=True)\n",
    "    assert len(acc_fl) == (n_blocks * n_supertrials * n_flanker), \"Check your data length!\"\n",
    "\n",
    "    blockAcc_wm = data[\"supertrial_blockAcc_wm\"].dropna().reset_index(drop=True)\n",
    "    assert len(blockAcc_wm) == n_blocks, \"Check your data length!\"\n",
    "\n",
    "    fl_supertrial_acc = [np.mean(i) for i in chunk_list(list(acc_fl), 8)]\n",
    "    assert len(fl_supertrial_acc) == (n_blocks * n_supertrials), \"Check your data length!\"\n",
    "    \n",
    "    blockAcc_fl = [np.mean(i) for i in chunk_list(list(fl_supertrial_acc), 6)]\n",
    "    assert len(blockAcc_fl) == n_blocks, \"Check your data length!\"\n",
    "    \n",
    "    fl_stim = data[\"flanker_stim\"].dropna().reset_index(drop=True)\n",
    "    assert len(fl_stim) == (n_blocks * n_supertrials * n_flanker), \"Check your data length!\"\n",
    "\n",
    "    for i, key in enumerate(list(data[\"task_stim_keyResp.rt\"])):\n",
    "        if (pd.isnull(key) and pd.notnull(list(data[\"fl_accuracy\"])[i])) :\n",
    "            data[\"task_stim_keyResp.rt\"].iloc[i] = \"None\"      \n",
    "    \n",
    "    congruent = data[\"congruent\"].dropna().reset_index(drop=True)\n",
    "    assert len(congruent) == (n_blocks * n_supertrials * n_flanker), \"Check your data length!\"\n",
    "\n",
    "    #print(\"Accuracy check...\")\n",
    "    if np.mean(acc_norder) < 0.7 or np.mean(acc_fl) < 0.7:\n",
    "        print (\"Low accuracy!\")\n",
    "        print(\"WM accuracy: {}\\nFlanker accuracy: {}\".format(round(np.mean(acc_norder), 4), round(np.mean(acc_fl), 4)))\n",
    "    else:\n",
    "        print (\"All accuracies > 0.7\")\n",
    "        print(\"WM accuracy: {}\\nFlanker accuracy: {}\".format(round(np.mean(acc_norder), 4), round(np.mean(acc_fl), 4)))\n",
    "    print(\"\")\n",
    "\n",
    "    # rt_trial = data[\"task_stim_keyResp.rt\"].dropna().reset_index(drop=True)\n",
    "# rt_trial = [i.split(\",\")for i in list(rt_trial)]\n",
    "# rt_trial[0]\n",
    "    \n",
    "    wm_acc_data = pd.DataFrame({\n",
    "    \"acc_order\": acc_order,\n",
    "    \"acc_norder\": acc_norder,\n",
    "    \"acc_fl\": fl_supertrial_acc,\n",
    "    \"wm_load\": ([4]*n_supertrials + [5]*n_supertrials) * (int(n_blocks/2))\n",
    "    })\n",
    "\n",
    "    fl_error_wm_acc_norder_1_4 = wm_acc_data[(wm_acc_data[\"acc_fl\"] == 0.875) & (wm_acc_data[\"wm_load\"] == 4)].acc_norder.mean()\n",
    "    fl_error_wm_acc_norder_1_5 = wm_acc_data[(wm_acc_data[\"acc_fl\"] == 0.875) & (wm_acc_data[\"wm_load\"] == 5)].acc_norder.mean()\n",
    "    fl_error_wm_acc_norder_0_4 = wm_acc_data[(wm_acc_data[\"acc_fl\"] == 1) & (wm_acc_data[\"wm_load\"] == 4)].acc_norder.mean()\n",
    "    fl_error_wm_acc_norder_0_5 = wm_acc_data[(wm_acc_data[\"acc_fl\"] == 1) & (wm_acc_data[\"wm_load\"] == 5)].acc_norder.mean()\n",
    "    fl_error_wm_acc_norder_many_4 = wm_acc_data[(wm_acc_data[\"acc_fl\"] < 0.875) & (wm_acc_data[\"wm_load\"] == 4)].acc_norder.mean()\n",
    "    fl_error_wm_acc_norder_many_5 = wm_acc_data[(wm_acc_data[\"acc_fl\"] < 0.875) & (wm_acc_data[\"wm_load\"] == 5)].acc_norder.mean()\n",
    "    \n",
    "    acc_order_4 = wm_acc_data[wm_acc_data[\"wm_load\"] == 4].acc_order.mean()\n",
    "    acc_order_5 = wm_acc_data[wm_acc_data[\"wm_load\"] == 5].acc_order.mean()\n",
    "    acc_norder_4 = wm_acc_data[wm_acc_data[\"wm_load\"] == 4].acc_norder.mean()\n",
    "    acc_norder_5 = wm_acc_data[wm_acc_data[\"wm_load\"] == 5].acc_norder.mean()\n",
    "    \n",
    "    \n",
    "    rt_data = pd.DataFrame({\"wm_load\": ([4]*(n_flanker*n_supertrials) + [5]*(n_flanker*n_supertrials)) * (int(n_blocks/2)),\n",
    "        \"rt\": list(pd.concat([data[\"flanker_stim\"].dropna(), data[\"task_stim_keyResp.rt\"]], axis=1).dropna()[\"task_stim_keyResp.rt\"]),\n",
    "                            \"congruent\": congruent,\n",
    "                            \"acc\": acc_fl,\n",
    "                           \"fl_stim\": fl_stim\n",
    "                           }\n",
    "                          )\n",
    "    \n",
    "    assert len(rt_data) == (n_blocks * n_supertrials * n_flanker), \"Check your data length!\"\n",
    "    \n",
    "    rt_data[\"rt\"] = convert_strings_to_float_lists(rt_data[\"rt\"])\n",
    "    rt_data[\"rt\"] = [\"N\" if i == \"None\" else i for i in rt_data[\"rt\"]]\n",
    "    \n",
    "    rt_data[\"rt_m\"] = [i[0] for i in rt_data[\"rt\"]]\n",
    "    rt_data[\"rt\"] = [i[0] if len(i) == 1 else \"M\" for i in rt_data[\"rt\"]]\n",
    "    \n",
    "    rt_data[\"rt\"] = [i * 1000 if type(i) == float else i for i in rt_data[\"rt\"]]\n",
    "    rt_data[\"rt_m\"] = [i * 1000 if type(i) == float else i for i in rt_data[\"rt_m\"]]\n",
    "    \n",
    "    rt_data['rt_clean'] = pd.to_numeric(rt_data['rt'], errors='coerce')\n",
    "    rt_data['rt_m'] = pd.to_numeric(rt_data['rt_m'], errors='coerce')\n",
    "\n",
    "    good_letters = ['B', 'b', 'D', 'd',\n",
    "    'F', 'f', 'G', 'g', 'H', 'h',\n",
    "    'J', 'j', 'K', 'k', #'L',\n",
    "    'M', 'm', 'N', 'n', 'P', 'p',\n",
    "    'Q', 'q', 'R', 'r',\n",
    "    'T', 't',]\n",
    "\n",
    "    good_rt_data = rt_data[rt_data['fl_stim'].str.contains('|'.join(good_letters))]\n",
    "    \n",
    "    assert len(rt_data) == (n_blocks * n_supertrials * n_flanker), \"Check your data length!\"\n",
    "    \n",
    "    mean_fl_acc_4 = round(rt_data[(rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 4)].acc.mean(), 2)\n",
    "    mean_fl_acc_5 = round(rt_data[(rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 5)].acc.mean(), 2)\n",
    "    acc_con_4 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 4)].acc.mean(), 2)\n",
    "    acc_con_5 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 5)].acc.mean(), 2)\n",
    "    acc_incon_4 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 4)].acc.mean(), 2)\n",
    "    acc_incon_5 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 5)].acc.mean(), 2)\n",
    "    \n",
    "    rt_con_corr_4 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 1) & (rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    rt_con_corr_5 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 1) & (rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "    rt_incon_corr_4 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 1) & (rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    rt_incon_corr_5 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 1) & (rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "    rt_con_incorr_4 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 0) & (rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    rt_con_incorr_5 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 0) & (rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "    rt_incon_incorr_4 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 0) & (rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    rt_incon_incorr_5 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 0) & (rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "\n",
    "    good_rt_con_corr_4 = round(good_rt_data[(good_rt_data[\"congruent\"] == 1) & (good_rt_data[\"rt_m\"] > 150) & (good_rt_data[\"acc\"] == 1) & (good_rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    good_rt_con_corr_5 = round(good_rt_data[(good_rt_data[\"congruent\"] == 1) & (good_rt_data[\"rt_m\"] > 150) & (good_rt_data[\"acc\"] == 1) & (good_rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "    good_rt_incon_corr_4 = round(good_rt_data[(good_rt_data[\"congruent\"] == 0) & (good_rt_data[\"rt_m\"] > 150) & (good_rt_data[\"acc\"] == 1) & (good_rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    good_rt_incon_corr_5 = round(good_rt_data[(good_rt_data[\"congruent\"] == 0) & (good_rt_data[\"rt_m\"] > 150) & (good_rt_data[\"acc\"] == 1) & (good_rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "    good_rt_con_incorr_4 = round(good_rt_data[(good_rt_data[\"congruent\"] == 1) & (good_rt_data[\"rt_m\"] > 150) & (good_rt_data[\"acc\"] == 0) & (good_rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    good_rt_con_incorr_5 = round(good_rt_data[(good_rt_data[\"congruent\"] == 1) & (good_rt_data[\"rt_m\"] > 150) & (good_rt_data[\"acc\"] == 0) & (good_rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "    good_rt_incon_incorr_4 = round(good_rt_data[(good_rt_data[\"congruent\"] == 0) & (good_rt_data[\"rt_m\"] > 150) & (good_rt_data[\"acc\"] == 0) & (good_rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    good_rt_incon_incorr_5 = round(good_rt_data[(good_rt_data[\"congruent\"] == 0) & (good_rt_data[\"rt_m\"] > 150) & (good_rt_data[\"acc\"] == 0) & (good_rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "    \n",
    "    # rt_data[\"pes\"] = np.nan\n",
    "    # rt_data[\"pea\"] = np.nan\n",
    "    # for i in range(len(rt_data)-1):\n",
    "    #     if rt_data[\"acc\"][i] < 1:\n",
    "    #         pes = rt_data[\"rt_clean\"][i+1] - rt_data[\"rt_clean\"][i]\n",
    "    #         rt_data[\"pes\"][i+1] = pes\n",
    "    # pes = rt_data[\"pes\"].mean()\n",
    "\n",
    "    #print(\"sub: {}\".format(sub))\n",
    "    # print(\"congruent RT: {} ms\".format(rt_con))\n",
    "    # print(\"congruent acc: {}\".format(acc_con))\n",
    "    # print(\"incongruent RT: {} ms\".format(rt_incon))\n",
    "    # print(\"incongruent acc: {}\".format(acc_incon))\n",
    "    print(\"\")\n",
    "    print(\"-----------\")\n",
    "\n",
    "    chi_data = pd.DataFrame({\n",
    "    \"wm_error\":[1 if i<1 else 0 for i in acc_order],\n",
    "    \"fl_error\":[1 if i<1 else 0 for i in fl_supertrial_acc]\n",
    "    })\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(pd.crosstab(chi_data[\"wm_error\"], chi_data[\"fl_error\"]))\n",
    "    crosstab = pd.crosstab(chi_data[\"wm_error\"], chi_data[\"fl_error\"]).stack()\n",
    "    wm_err0_fl_err0 = crosstab[0,0] # wm-err 0 fl-err 0\n",
    "    wm_err0_fl_err1 = crosstab[0,1] # wm-err 0 fl-err 1\n",
    "    wm_err1_fl_err0 = crosstab[1,0] # wm-err 1 fl-err 0\n",
    "    wm_err1_fl_err1 = crosstab[1,1] # wm-err 1 fl-err 1\n",
    "\n",
    "    intersection = dict({\n",
    "    \"shown_letters\":[],\n",
    "    \"response\":[],\n",
    "    \"fl_middle\":[],\n",
    "    \"shown_x_flanker\":[],\n",
    "    \"response_x_flanker\":[],\n",
    "    \"difference\":[],\n",
    "    \"acc_order\":[],\n",
    "    \"acc_norder\":[],\n",
    "    \"acc_fl\":[],\n",
    "    \"congruent\":[],\n",
    "    \"acc\":[],\n",
    "    })\n",
    "    for i in range(n_supertrials * n_blocks):\n",
    "        fl_middle= \"\".join([fl[2] for fl in chunk_list(list(fl_stim), 8)[i]])\n",
    "        congr = [fl for fl in chunk_list(list(congruent), 8)[i]]\n",
    "        accuracy = [ac for ac in chunk_list(list(acc_fl), 8)[i]]\n",
    "        intersection[\"shown_letters\"].append(shown_letters[i])\n",
    "        intersection[\"response\"].append(wm_response[i])\n",
    "        intersection[\"fl_middle\"].append(fl_middle)\n",
    "        intersection[\"shown_x_flanker\"].append(set(shown_letters[i].upper()).intersection(fl_middle.upper()))\n",
    "        intersection[\"response_x_flanker\"].append(set(wm_response[i].upper()).intersection(fl_middle.upper()))\n",
    "        intersection[\"difference\"].append(\n",
    "            set(wm_response[i].upper()).intersection(fl_middle.upper()).\\\n",
    "            difference(set(shown_letters[i].upper()).intersection(fl_middle.upper()))\n",
    "        )\n",
    "        intersection[\"acc_order\"].append(acc_order[i])\n",
    "        intersection[\"acc_norder\"].append(acc_norder[i])\n",
    "        intersection[\"acc_fl\"].append(fl_supertrial_acc[i])\n",
    "        intersection[\"congruent\"].append(congr)\n",
    "        intersection[\"acc\"].append(accuracy)\n",
    "\n",
    "    intersec_data = pd.DataFrame(intersection)\n",
    "    intersec_data[\"wm_load\"] = ([4]*n_supertrials + [5]*n_supertrials) * (int(n_blocks/2))\n",
    "    intersec_data[\"diff_con\"] = np.nan\n",
    "    intersec_data[\"diff_incon\"] = np.nan\n",
    "    for i, diff in enumerate(intersec_data[\"difference\"]): #correct\n",
    "        con_ct = 0\n",
    "        incon_ct = 0\n",
    "        for letter in diff:\n",
    "            ind = intersec_data[\"fl_middle\"][i].upper().index(letter)\n",
    "            if (intersec_data[\"congruent\"][i][ind] == 1) and (intersec_data[\"acc\"][i][ind] == 1):\n",
    "                con_ct +=1\n",
    "            elif (intersec_data[\"congruent\"][i][ind] == 0) and (intersec_data[\"acc\"][i][ind] == 1):\n",
    "                incon_ct +=1\n",
    "        intersec_data[\"diff_con\"][i] = con_ct\n",
    "        intersec_data[\"diff_incon\"][i] = incon_ct\n",
    "\n",
    "    intersec_data[\"len_difference\"] = [len(i) for i in intersec_data[\"difference\"]]\n",
    "    intersec_data[\"1h_difference\"] = [1 if len(i)>0 else 0 for i in intersec_data[\"difference\"]]\n",
    "    mean_letters_from_fl_err_4 = intersec_data[(intersec_data[\"acc_fl\"] < 1) & (intersec_data[\"wm_load\"] == 4)].len_difference.mean()\n",
    "    mean_letters_from_fl_err_5 = intersec_data[(intersec_data[\"acc_fl\"] < 1) & (intersec_data[\"wm_load\"] == 5)].len_difference.mean()\n",
    "    mean_letters_from_fl_corr_4 = intersec_data[(intersec_data[\"acc_fl\"] == 1) & (intersec_data[\"wm_load\"] == 4)].len_difference.mean()\n",
    "    mean_letters_from_fl_corr_5 = intersec_data[(intersec_data[\"acc_fl\"] == 1) & (intersec_data[\"wm_load\"] == 5)].len_difference.mean()\n",
    "\n",
    "    intersec_subset = intersec_data[(intersec_data[\"difference\"] != set()) & (intersec_data[\"acc_fl\"] == 0.875)]\n",
    "    cnt = []\n",
    "    for i in range(len(intersec_subset)):\n",
    "        ind_err = intersec_subset.acc.reset_index(drop=True)[i].index(0)\n",
    "        inds_letter = [intersec_subset.fl_middle.reset_index(drop=True)[i].upper().index(letter) for letter in intersec_subset.difference.reset_index(drop=True)[i]]\n",
    "        if any([ind_err == il for il in inds_letter]):\n",
    "            cnt.append(1)\n",
    "        else:\n",
    "            cnt.append(0)\n",
    "    intersec_subset[\"cnt\"] = cnt\n",
    "    intersec_subset[\"cnt_n\"] = len(cnt)\n",
    "    cnt_mean = intersec_subset[\"cnt\"].mean()\n",
    "    subsets.append(intersec_subset)\n",
    "\n",
    "    #if np.mean(acc_norder) > 0.7 and np.mean(acc_fl) > 0.7:\n",
    "    wme_dict[\"sub\"].append(sub)\n",
    "    wme_dict[\"acc_fl\"].append(np.mean(acc_fl))\n",
    "    wme_dict[\"acc_norder\"].append(np.mean(acc_norder))\n",
    "    wme_dict[\"4-1_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_1_4)\n",
    "    wme_dict[\"5-1_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_1_5)\n",
    "    wme_dict[\"4-0_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_0_4)\n",
    "    wme_dict[\"5-0_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_0_5)\n",
    "    wme_dict[\"4-many_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_many_4)\n",
    "    wme_dict[\"5-many_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_many_5)\n",
    "    wme_dict[\"4-acc_con\"].append(acc_con_4)\n",
    "    wme_dict[\"5-acc_con\"].append(acc_con_5)\n",
    "    wme_dict[\"4-acc_incon\"].append(acc_incon_4)\n",
    "    wme_dict[\"5-acc_incon\"].append(acc_incon_5)\n",
    "    wme_dict[\"4-acc_fl\"].append(mean_fl_acc_4)\n",
    "    wme_dict[\"5-acc_fl\"].append(mean_fl_acc_5)\n",
    "    wme_dict[\"1_fl_error_trials\"].append(round(len(intersec_data[intersec_data[\"acc_fl\"]==0.875])/len(intersec_data[intersec_data[\"acc_fl\"]<1]), 2))\n",
    "    wme_dict[\"4-rt_con_corr\"].append(rt_con_corr_4)\n",
    "    wme_dict[\"5-rt_con_corr\"].append(rt_con_corr_5)\n",
    "    wme_dict[\"4-rt_incon_corr\"].append(rt_incon_corr_4)\n",
    "    wme_dict[\"5-rt_incon_corr\"].append(rt_incon_corr_5)\n",
    "    wme_dict[\"4-rt_con_incorr\"].append(rt_con_incorr_4)\n",
    "    wme_dict[\"5-rt_con_incorr\"].append(rt_con_incorr_5)\n",
    "    wme_dict[\"4-rt_incon_incorr\"].append(rt_incon_incorr_4)\n",
    "    wme_dict[\"5-rt_incon_incorr\"].append(rt_incon_incorr_5)\n",
    "    wme_dict[\"4-good_rt_con_corr\"].append(good_rt_con_corr_4)\n",
    "    wme_dict[\"5-good_rt_con_corr\"].append(good_rt_con_corr_5)\n",
    "    wme_dict[\"4-good_rt_incon_corr\"].append(good_rt_incon_corr_4)\n",
    "    wme_dict[\"5-good_rt_incon_corr\"].append(good_rt_incon_corr_5)\n",
    "    wme_dict[\"4-good_rt_con_incorr\"].append(good_rt_con_incorr_4)\n",
    "    wme_dict[\"5-good_rt_con_incorr\"].append(good_rt_con_incorr_5)\n",
    "    wme_dict[\"4-good_rt_incon_incorr\"].append(good_rt_incon_incorr_4)\n",
    "    wme_dict[\"5-good_rt_incon_incorr\"].append(good_rt_incon_incorr_5)\n",
    "    #wme_dict[\"pes\"].append(pes)\n",
    "    wme_dict[\"4-acc_order\"].append(acc_order_4)\n",
    "    wme_dict[\"5-acc_order\"].append(acc_order_5)\n",
    "    wme_dict[\"4-acc_norder\"].append(acc_norder_4)\n",
    "    wme_dict[\"5-acc_norder\"].append(acc_norder_5)\n",
    "    wme_dict[\"wm_err0_fl_err0\"].append(wm_err0_fl_err0)\n",
    "    wme_dict[\"wm_err0_fl_err1\"].append(wm_err0_fl_err1)\n",
    "    wme_dict[\"wm_err1_fl_err0\"].append(wm_err1_fl_err0)\n",
    "    wme_dict[\"wm_err1_fl_err1\"].append(wm_err1_fl_err1)\n",
    "    wme_dict[\"chi2\"].append(p)\n",
    "    wme_dict[\"diff_con\"].append(intersec_data[\"diff_con\"].mean())\n",
    "    wme_dict[\"diff_incon\"].append(intersec_data[\"diff_incon\"].mean())\n",
    "    wme_dict[\"4-mean_letters_from_fl_err\"].append(mean_letters_from_fl_err_4)\n",
    "    wme_dict[\"5-mean_letters_from_fl_err\"].append(mean_letters_from_fl_err_5)\n",
    "    wme_dict[\"4-mean_letters_from_fl_corr\"].append(mean_letters_from_fl_corr_4)\n",
    "    wme_dict[\"5-mean_letters_from_fl_corr\"].append(mean_letters_from_fl_corr_5)\n",
    "    wme_dict[\"cnt_mean\"].append(cnt_mean)\n",
    "    wme_dict[\"cnt_n\"].append(intersec_subset[\"cnt_n\"].mean())\n",
    "    wme_dict[\"hand\"].append(counterbalance[0])\n",
    "    wme_dict[\"repeat\"].append(counterbalance[1])\n",
    "\n",
    "    fl_trials = pd.DataFrame(\n",
    "        {\"target\": [i[2] for i in fl_stim],\n",
    "        \"congruent\": congruent,\n",
    "        \"acc\": acc_fl,\n",
    "        \"err_hand\": \"NA\",\n",
    "        }\n",
    "    )\n",
    "    labels = []\n",
    "    for i in range(len(fl_trials)):\n",
    "        if fl_trials[\"congruent\"][i] == 0 and fl_trials[\"acc\"][i] == 0: # incon-error\n",
    "            labels.append(\"incon-error\")\n",
    "        elif fl_trials[\"congruent\"][i] == 0 and fl_trials[\"acc\"][i] == 1: # incon-correct\n",
    "            labels.append(\"incon-correct\")\n",
    "        elif fl_trials[\"congruent\"][i] == 1 and fl_trials[\"acc\"][i] == 1: # con-correct\n",
    "            labels.append(\"con-correct\")\n",
    "        else:\n",
    "            labels.append(\"NA\")\n",
    "    fl_trials[\"label\"] = labels\n",
    "    \n",
    "    post_labels = []\n",
    "    post_labels.append(\"NA\")\n",
    "    for i in range(1, len(fl_trials)):\n",
    "        if fl_trials[\"label\"][i-1] == \"incon-correct\":\n",
    "            post_labels.append(\"post incon-correct\")\n",
    "        elif fl_trials[\"label\"][i-1] == \"incon-error\":\n",
    "            post_labels.append(\"post incon-error\")\n",
    "        elif fl_trials[\"label\"][i-1] == \"con-correct\":\n",
    "            post_labels.append(\"post con-correct\")\n",
    "        else:\n",
    "            post_labels.append(\"NA\")\n",
    "    fl_trials[\"post_label\"] = post_labels\n",
    "\n",
    "    if counterbalance[0] == \"L\":\n",
    "        for i in range(len(fl_trials)):\n",
    "            if fl_trials[\"acc\"][i] == 0:\n",
    "                if fl_trials[\"target\"][i].isupper():\n",
    "                    fl_trials[\"err_hand\"][i] = \"R\"\n",
    "                else:\n",
    "                    fl_trials[\"err_hand\"][i] = \"L\"\n",
    "    elif counterbalance[0] == \"R\":\n",
    "        for i in range(len(fl_trials)):\n",
    "            if fl_trials[\"acc\"][i] == 0:\n",
    "                if fl_trials[\"target\"][i].isupper():\n",
    "                    fl_trials[\"err_hand\"][i] = \"L\"\n",
    "                else:\n",
    "                    fl_trials[\"err_hand\"][i] = \"R\"\n",
    "                    \n",
    "    fl_trials[\"target\"] = [i.upper() for i in fl_trials[\"target\"]]\n",
    "    \n",
    "    recalls = []\n",
    "    for i in wm_response:\n",
    "        recalls += [i] * 8\n",
    "    \n",
    "    fl_trials[\"recall\"] = recalls\n",
    "    fl_trials[\"load\"] = ([4]*n_flanker*n_supertrials + [5]*n_flanker*n_supertrials) * (int(n_blocks/2))\n",
    "    \n",
    "    appeared = []\n",
    "    for i in range(len(fl_trials)):\n",
    "        if fl_trials[\"target\"][i] in fl_trials[\"recall\"][i]:\n",
    "            appeared.append(True)\n",
    "        else:\n",
    "            appeared.append(False)\n",
    "\n",
    "    fl_trials[\"appeared\"] = appeared\n",
    "\n",
    "    try:\n",
    "        ratio_incon_correct = len((fl_trials[(fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_incon_correct = np.nan\n",
    "\n",
    "    try:\n",
    "        ratio_incon_correct_4 = len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_incon_correct_4 = np.nan\n",
    "\n",
    "    try:\n",
    "        ratio_incon_correct_5 = len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_incon_correct_5 = np.nan\n",
    "\n",
    "    try:    \n",
    "        ratio_post_incon_correct = len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_post_incon_correct = np.nan\n",
    "\n",
    "    try:\n",
    "        ratio_post_incon_correct_4 = len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_post_incon_correct_4 = np.nan\n",
    "    \n",
    "    try:\n",
    "        ratio_post_incon_correct_5 = len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "       ratio_post_incon_correct_5 = np.nan\n",
    "    \n",
    "    try:\n",
    "        ratio_incon_error = len((fl_trials[(fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_incon_error = np.nan\n",
    "        \n",
    "    try:\n",
    "        ratio_incon_error_4 = len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "       ratio_incon_error_4 = np.nan\n",
    "        \n",
    "    try:\n",
    "        ratio_incon_error_5 = len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_incon_error_5 = np.nan\n",
    "    \n",
    "    try:\n",
    "        ratio_post_incon_error = len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_post_incon_error = np.nan\n",
    "    \n",
    "    try:\n",
    "        ratio_post_incon_error_4 = len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_post_incon_error_4 = np.nan\n",
    "    \n",
    "    try:\n",
    "        ratio_post_incon_error_5 = len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_post_incon_error_5 = np.nan\n",
    "\n",
    "\n",
    "    try:\n",
    "        R_ratio_incon_correct = len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        R_ratio_incon_correct = np.nan\n",
    "\n",
    "    try:    \n",
    "        R_ratio_post_incon_correct = len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        R_ratio_post_incon_correct = np.nan\n",
    "    \n",
    "    try:\n",
    "        R_ratio_incon_error = len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        R_ratio_incon_error = np.nan\n",
    "        \n",
    "    try:\n",
    "        R_ratio_post_incon_error = len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        R_ratio_post_incon_error = np.nan\n",
    "\n",
    "    try:\n",
    "        L_ratio_incon_correct = len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        L_ratio_incon_correct = np.nan\n",
    "\n",
    "    try:    \n",
    "        L_ratio_post_incon_correct = len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        L_ratio_post_incon_correct = np.nan\n",
    "    \n",
    "    try:\n",
    "        L_ratio_incon_error = len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        L_ratio_incon_error = np.nan\n",
    "        \n",
    "    try:\n",
    "        L_ratio_post_incon_error = len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        L_ratio_post_incon_error = np.nan\n",
    "        \n",
    "    wme_dict[\"ratio_incon_correct\"].append(ratio_incon_correct)\n",
    "    wme_dict[\"4-ratio_incon_correct\"].append(ratio_incon_correct_4)\n",
    "    wme_dict[\"5-ratio_incon_correct\"].append(ratio_incon_correct_5)\n",
    "    \n",
    "    wme_dict[\"ratio_post_incon_correct\"].append(ratio_post_incon_correct)\n",
    "    wme_dict[\"4-ratio_post_incon_correct\"].append(ratio_post_incon_correct_4)\n",
    "    wme_dict[\"5-ratio_post_incon_correct\"].append(ratio_post_incon_correct_5)\n",
    "\n",
    "    wme_dict[\"ratio_incon_error\"].append(ratio_incon_error)\n",
    "    wme_dict[\"4-ratio_incon_error\"].append(ratio_incon_error_4)\n",
    "    wme_dict[\"5-ratio_incon_error\"].append(ratio_incon_error_5)\n",
    "    \n",
    "    wme_dict[\"ratio_post_incon_error\"].append(ratio_post_incon_error)\n",
    "    wme_dict[\"4-ratio_post_incon_error\"].append(ratio_post_incon_error_4)\n",
    "    wme_dict[\"5-ratio_post_incon_error\"].append(ratio_post_incon_error_5)\n",
    "\n",
    "    wme_dict[\"R_ratio_incon_correct\"].append(R_ratio_incon_correct)\n",
    "    wme_dict[\"L_ratio_incon_correct\"].append(L_ratio_incon_correct)\n",
    "    wme_dict[\"R_ratio_post_incon_correct\"].append(R_ratio_post_incon_correct)\n",
    "    wme_dict[\"L_ratio_post_incon_correct\"].append(L_ratio_post_incon_correct)\n",
    "    wme_dict[\"R_ratio_incon_error\"].append(R_ratio_incon_error)\n",
    "    wme_dict[\"L_ratio_incon_error\"].append(L_ratio_incon_error)\n",
    "    wme_dict[\"R_ratio_post_incon_error\"].append(R_ratio_post_incon_error)\n",
    "    wme_dict[\"L_ratio_post_incon_error\"].append(L_ratio_post_incon_error)\n",
    "\n",
    "    try:\n",
    "        ratio_con = len((fl_trials[(fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_con = np.nan\n",
    "\n",
    "    try:\n",
    "        ratio_incon = len((fl_trials[(fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_incon = np.nan\n",
    "\n",
    "    try:\n",
    "        ratio_post_con = len((fl_trials[(fl_trials[\"post_label\"] == \"post con-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"post_label\"] == \"post con-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_post_con = np.nan\n",
    "\n",
    "    try:\n",
    "        ratio_post_incon = len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_post_incon = np.nan\n",
    "\n",
    "    try:\n",
    "        ratio_post_error_con = len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_post_error_con = np.nan\n",
    "\n",
    "    try:\n",
    "        ratio_post_error_incon = len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        ratio_post_error_incon = np.nan\n",
    "\n",
    "\n",
    "\n",
    "    try:\n",
    "        R_ratio_con = len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        R_ratio_con = np.nan\n",
    "\n",
    "    try:\n",
    "        L_ratio_con = len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        L_ratio_con = np.nan\n",
    "\n",
    "    try:\n",
    "        R_ratio_incon = len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        R_ratio_incon = np.nan\n",
    "\n",
    "    try:\n",
    "        L_ratio_incon = len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        L_ratio_incon = np.nan\n",
    "\n",
    "    try:\n",
    "        R_ratio_post_con = len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post con-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post con-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        R_ratio_post_con = np.nan\n",
    "\n",
    "    try:\n",
    "        L_ratio_post_con = len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post con-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post con-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        L_ratio_post_con = np.nan\n",
    "\n",
    "    try:\n",
    "        R_ratio_post_incon = len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        R_ratio_post_incon = np.nan\n",
    "\n",
    "    try:\n",
    "        L_ratio_post_incon = len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        L_ratio_post_incon = np.nan\n",
    "  \n",
    "    try:\n",
    "        R_ratio_post_error_con = len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        R_ratio_post_error_con = np.nan\n",
    "\n",
    "    try:\n",
    "        L_ratio_post_error_con = len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 1) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        L_ratio_post_error_con = np.nan\n",
    " \n",
    "    try:\n",
    "        R_ratio_post_error_incon = len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"R\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        R_ratio_post_error_incon = np.nan\n",
    "\n",
    "    try:\n",
    "        L_ratio_post_error_incon = len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "        len((fl_trials[(fl_trials[\"err_hand\"] == \"L\") & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"congruent\"] == 0) & (fl_trials[\"appeared\"] == False)]))\n",
    "    except:\n",
    "        L_ratio_post_error_incon = np.nan\n",
    "\n",
    "    wme_dict[\"ratio_con\"].append(ratio_con)\n",
    "    wme_dict[\"ratio_incon\"].append(ratio_incon)\n",
    "    wme_dict[\"ratio_post_con\"].append(ratio_post_con)\n",
    "    wme_dict[\"ratio_post_incon\"].append(ratio_post_incon)\n",
    "    wme_dict[\"ratio_post_error_con\"].append(ratio_post_error_con)\n",
    "    wme_dict[\"ratio_post_error_incon\"].append(ratio_post_error_incon)\n",
    "\n",
    "    wme_dict[\"L_ratio_con\"].append(L_ratio_con)\n",
    "    wme_dict[\"R_ratio_con\"].append(R_ratio_con)\n",
    "    wme_dict[\"L_ratio_incon\"].append(L_ratio_incon)\n",
    "    wme_dict[\"R_ratio_incon\"].append(R_ratio_incon)\n",
    "    wme_dict[\"L_ratio_post_con\"].append(L_ratio_post_con)\n",
    "    wme_dict[\"R_ratio_post_con\"].append(R_ratio_post_con)\n",
    "    wme_dict[\"L_ratio_post_incon\"].append(L_ratio_post_incon)\n",
    "    wme_dict[\"R_ratio_post_incon\"].append(R_ratio_post_incon)\n",
    "    wme_dict[\"L_ratio_post_error_con\"].append(L_ratio_post_error_con)\n",
    "    wme_dict[\"R_ratio_post_error_con\"].append(R_ratio_post_error_con)\n",
    "    wme_dict[\"L_ratio_post_error_incon\"].append(L_ratio_post_error_incon)\n",
    "    wme_dict[\"R_ratio_post_error_incon\"].append(R_ratio_post_error_incon)\n",
    "\n",
    "    big_list = [i[2].upper() for i in fl_stim]\n",
    "    chunk_size = 8\n",
    "    result = chunk_list(big_list, chunk_size)\n",
    "    result = [\"\".join(i) for i in result]\n",
    "    \n",
    "    list1 = [\"\".join(i) for i in result]\n",
    "    list2 = [i.upper() for i in shown_letters]\n",
    "    repeat_cnt = 0\n",
    "    not_repeat_cnt = 0\n",
    "    for string1, string2 in zip(list1, list2):\n",
    "        if has_common_letter(string1, string2):\n",
    "            repeat_cnt +=1\n",
    "        else:\n",
    "            not_repeat_cnt +=1\n",
    "\n",
    "    wme_dict[\"repeat_cnt\"].append(repeat_cnt)\n",
    "    wme_dict[\"not_repeat_cnt\"].append(not_repeat_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac2647-f527-40bd-aebb-167a27f57642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a650f57-a85c-4747-baaf-88631e70e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf166701-725b-48a5-9e34-6bc79301be1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fl_trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb338910-c582-4579-91bd-48cbd9c0b1a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T18:22:37.576263Z",
     "start_time": "2024-02-03T18:22:37.415288Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wme_data = pd.DataFrame(wme_dict)\n",
    "wme_data = wme_data.round(2)\n",
    "wme_data = wme_data[(wme_data[\"acc_fl\"]>0.7) & (wme_data[\"4-acc_norder\"]>0.7)].reset_index(drop=True)\n",
    "wme_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f648590a-441b-46b1-9950-14c5454126ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    len(wme_data[wme_data[\"hand\"]==\"R\"]),\n",
    "    len(wme_data[wme_data[\"hand\"]==\"L\"]),\n",
    "    len(wme_data[wme_data[\"repeat\"]==\"No\"]),\n",
    "    len(wme_data[wme_data[\"repeat\"]==\"Yes\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62fd30-3504-498d-a1a3-7a3774bdb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_ratio_incon_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aec830-a9e9-4fc3-9b37-c89a15a1e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "wme_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b80b5d12384946",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ba059a-b8b3-4d7e-8a28-ecbf136b8a23",
   "metadata": {},
   "source": [
    "### RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36394eaa-c6ae-4e74-b9e8-547b19b00868",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "pic_name = \"RT_LR.png\"\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[\\\n",
    "            ['4-rt_con_corr', '5-rt_con_corr', '4-rt_incon_corr', '5-rt_incon_corr',\n",
    "           '4-rt_con_incorr', '5-rt_con_incorr', '4-rt_incon_incorr',\n",
    "           '5-rt_incon_incorr',]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"RT (ms)\")\n",
    "plt.ylim(250, 900)\n",
    "\n",
    "#plt.savefig(path+\"{}\".format(pic_name), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c939494-0942-4f45-abb2-0d4e5da447e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "pic_name = \"good_RT_LR.png\"\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[\\\n",
    "            ['4-good_rt_con_corr', '5-good_rt_con_corr', '4-good_rt_incon_corr', '5-good_rt_incon_corr',\n",
    "           '4-good_rt_con_incorr', '5-good_rt_con_incorr', '4-good_rt_incon_incorr',\n",
    "           '5-good_rt_incon_incorr',]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"RT (ms)\")\n",
    "plt.ylim(250, 900)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc345efb-058d-4584-8598-9275347648e1",
   "metadata": {},
   "source": [
    "#### Counterbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97679d-d4e2-4a1b-adfc-820886e53e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "hand = \"L\"\n",
    "pic_name = \"RT_{}.png\".format(hand)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[wme_data[\"hand\"] == hand][\\\n",
    "            ['4-rt_con_corr', '5-rt_con_corr', '4-rt_incon_corr', '5-rt_incon_corr',\n",
    "       '4-rt_con_incorr', '5-rt_con_incorr', '4-rt_incon_incorr',\n",
    "       '5-rt_incon_incorr',]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"RT (ms)\")\n",
    "plt.ylim(250, 900)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e79c19-972b-4f8c-a6b1-927e9bed6428",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "repeat = \"No\"\n",
    "pic_name = \"RT_{}.png\".format(repeat)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[wme_data[\"repeat\"] == repeat][\\\n",
    "            ['4-rt_con_corr', '5-rt_con_corr', '4-rt_incon_corr', '5-rt_incon_corr',\n",
    "       '4-rt_con_incorr', '5-rt_con_incorr', '4-rt_incon_incorr',\n",
    "       '5-rt_incon_incorr',]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"RT (ms)\")\n",
    "plt.ylim(250, 900)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24237dbe-d9ad-4168-a8a1-c6cfe8932b0b",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aadb5e6-26b3-41fb-b285-2603a79b0c90",
   "metadata": {},
   "source": [
    "#### Flanker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d999a6d-9412-465b-ac19-21696e21230e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "pic_name = \"ACC_LR.png\"\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[\\\n",
    "            ['4-acc_con', '5-acc_con', '4-acc_incon', '5-acc_incon',]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "#boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.65, 1.05)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3559f10b-2f8e-4c06-b278-0b2369a90260",
   "metadata": {},
   "source": [
    "##### Counterbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb4de4e-8f12-4552-8e16-d9e873af56d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "hand = \"R\"\n",
    "pic_name = \"ACC_{}.png\".format(hand)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[wme_data[\"hand\"] == hand][\\\n",
    "            ['4-acc_con', '5-acc_con', '4-acc_incon', '5-acc_incon',]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "#boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.65, 1.05)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bc5860-a1ee-402d-af4d-76dfb7139f2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "repeat = \"Yes\"\n",
    "pic_name = \"ACC_{}.png\".format(repeat)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[wme_data[\"repeat\"] == repeat][\\\n",
    "            ['4-acc_con', '5-acc_con', '4-acc_incon', '5-acc_incon',]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "#boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.65, 1.05)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17fd273-5daa-4634-b069-65cac28292ce",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### WM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9207e-2adb-4007-b9bd-82e177686dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "pic_name = \"ACC_WM.png\"\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[\\\n",
    "            ['4-acc_order', '5-acc_order', '4-acc_norder', '5-acc_norder']\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "#boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.3, 1.05)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b2e21e-a1d6-4bbb-a2ad-52f3a089dc1a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Counterbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30d08a-c53e-4dfc-a728-e0237751bd9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "repeat = \"No\"\n",
    "pic_name = \"ACC_WM_{}.png\".format(repeat)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[wme_data[\"repeat\"] == repeat][\\\n",
    "            ['4-acc_order', '5-acc_order', '4-acc_norder', '5-acc_norder']\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "#boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.3, 1.05)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226e5108-c72f-4002-9d0e-e379de317047",
   "metadata": {},
   "source": [
    "### Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b13316-235a-478d-af98-7a245dc6f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "pic_name = \"RATIO.png\"\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[\\\n",
    "            ['ratio_con', 'ratio_incon', 'ratio_post_con', 'ratio_post_incon', \n",
    "            'ratio_incon_correct', 'ratio_incon_error', 'ratio_post_incon_correct', \n",
    "            'ratio_post_incon_error', 'ratio_post_error_con', 'ratio_post_error_incon']\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.ylim(-0.05, 1.05)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f42bb26-0467-4696-8593-c7671a777f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "pic_name = \"ERR_HAND_RATIO.png\"\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[\\\n",
    "            [\n",
    "            'L_ratio_con', 'R_ratio_con',\n",
    "             'L_ratio_incon', 'R_ratio_incon',\n",
    "             'L_ratio_post_con', 'R_ratio_post_con',\n",
    "             'L_ratio_post_incon', 'R_ratio_post_incon', \n",
    "             'L_ratio_post_incon_correct', 'R_ratio_post_incon_correct', \n",
    "            'L_ratio_post_incon_error', 'R_ratio_post_incon_error',\n",
    "             'L_ratio_post_error_con', 'R_ratio_post_error_con',\n",
    "             'L_ratio_post_error_incon', 'R_ratio_post_error_incon'\n",
    "            ]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=70)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.ylim(-0.05, 1.05)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d510007-ccb3-4cd5-a7f4-8e360c14613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wme_data[\\\n",
    "            [\n",
    "            'L_ratio_con', 'R_ratio_con',\n",
    "             'L_ratio_incon', 'R_ratio_incon',\n",
    "             'L_ratio_post_con', 'R_ratio_post_con',\n",
    "             'L_ratio_post_incon', 'R_ratio_post_incon', \n",
    "            'L_ratio_incon_correct', 'R_ratio_incon_correct',\n",
    "             'L_ratio_incon_error', 'R_ratio_incon_error',\n",
    "             'L_ratio_post_incon_correct', 'R_ratio_post_incon_correct', \n",
    "            'L_ratio_post_incon_error', 'R_ratio_post_incon_error',\n",
    "             'L_ratio_post_error_con', 'R_ratio_post_error_con',\n",
    "             'L_ratio_post_error_incon', 'R_ratio_post_error_incon']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735c570-e736-44d0-85b8-8a1be3c13a61",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Counterbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f27dae-34ed-4fb3-835c-f6cfeca10530",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/wme/\"\n",
    "repeat = \"No\"\n",
    "pic_name = \"RATIO_{}.png\".format(repeat)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "boxplot = sns.boxplot(data=wme_data[wme_data[\"repeat\"]==repeat][\\\n",
    "            ['ratio_con', 'ratio_incon', 'ratio_post_con', 'ratio_post_incon', \n",
    "            'ratio_incon_correct', 'ratio_incon_error', 'ratio_post_incon_correct', \n",
    "            'ratio_post_incon_error', 'ratio_post_error_con', 'ratio_post_error_incon']\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "boxplot.set_xticklabels(boxplot.get_xticklabels(), rotation=45)\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"Ratio\")\n",
    "plt.ylim(-0.05, 1.05)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name), bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2492833e4fd0fe",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Letter Flanker analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a0645-5050-4b37-8710-05e2324a7b81",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e26e528d82d1a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T18:10:21.934140Z",
     "start_time": "2024-02-03T18:10:21.907539Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "n_blocks = 12\n",
    "n_supertrials = 6\n",
    "n_flanker = 8\n",
    "subsets = []\n",
    "path = \"/Users/fzaki001/Documents/AHC5-rooms/WME/letter-flanker/data/\"\n",
    "subjects = sorted([i[8:10] for i in os.listdir(path) if i.endswith(\"csv\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b45cb84ffb704c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T18:10:22.662429Z",
     "start_time": "2024-02-03T18:10:22.512606Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "n_blocks = 6\n",
    "n_flanker = 40\n",
    "flanker_data = dict(\n",
    "    {\n",
    "    \"sub\": [],\n",
    "    \"acc\": [],\n",
    "    \"acc_con\": [],\n",
    "    \"acc_incon\": [],\n",
    "    \"rt\": [],\n",
    "    \"rt_con_corr\": [],\n",
    "    \"rt_incon_corr\": [],\n",
    "    \"rt_con_incorr\": [],\n",
    "    \"rt_incon_incorr\": [],\n",
    "    \"good_rt_con_corr\": [],\n",
    "    \"good_rt_incon_corr\": [],\n",
    "    \"good_rt_con_incorr\": [],\n",
    "    \"good_rt_incon_incorr\": [],\n",
    "    \"hand\": [],\n",
    "}\n",
    ")\n",
    "for sub in subjects:\n",
    "    print(sub)\n",
    "    data = pd.read_csv(\"{}sub-2800{}_letter-flanker_s1_r1_e1.csv\".format(path, sub))\n",
    "    counterbalance = data[\"hand\"][0]\n",
    "    start_index = data[\"flanker_stim\"].first_valid_index()\n",
    "    data = data.iloc[start_index:, :]\n",
    "    \n",
    "    acc_fl = data[\"fl_accuracy\"].dropna().reset_index(drop=True)\n",
    "    assert len(acc_fl) == (n_blocks * n_flanker), \"Check your data length!\"\n",
    "\n",
    "    # blockAcc_fl = [np.mean(i) for i in chunk_list(list(fl_supertrial_acc), 6)]\n",
    "    # assert len(blockAcc_fl) == n_blocks, \"Check your data length!\"\n",
    "\n",
    "    fl_stim = data[\"flanker_stim\"].dropna().reset_index(drop=True)\n",
    "    assert len(fl_stim) == (n_blocks * n_flanker), \"Check your data length!\"\n",
    "\n",
    "    congruent = data[\"congruent\"].dropna().reset_index(drop=True)\n",
    "    assert len(congruent) == (n_blocks * n_flanker), \"Check your data length!\"\n",
    "\n",
    "    for i, key in enumerate(list(data[\"task_stim_keyResp.rt\"])):\n",
    "        if (pd.isnull(key) and pd.notnull(list(data[\"fl_accuracy\"])[i])) :\n",
    "            data[\"task_stim_keyResp.rt\"].iloc[i] = \"None\"\n",
    "\n",
    "    rt_data = pd.DataFrame({\"rt\": list(pd.concat([data[\"flanker_stim\"].dropna(), data[\"task_stim_keyResp.rt\"]],axis=1).dropna()[\"task_stim_keyResp.rt\"]),\n",
    "        \"congruent\": congruent,\n",
    "        \"acc\": acc_fl,\n",
    "        \"fl_stim\": fl_stim}\n",
    "            )\n",
    "    assert len(rt_data) == (n_blocks * n_flanker), \"Check your data length!\"\n",
    "\n",
    "    rt_data[\"rt\"] = convert_strings_to_float_lists(rt_data[\"rt\"])\n",
    "    rt_data[\"rt\"] = [\"N\" if i == \"None\" else i for i in rt_data[\"rt\"]]\n",
    "\n",
    "    rt_data[\"rt_m\"] = [i[0] for i in rt_data[\"rt\"]]\n",
    "    rt_data[\"rt\"] = [i[0] if len(i) == 1 else \"M\" for i in rt_data[\"rt\"]]\n",
    "\n",
    "    rt_data[\"rt\"] = [i * 1000 if type(i) == float else i for i in rt_data[\"rt\"]]\n",
    "    rt_data[\"rt_m\"] = [i * 1000 if type(i) == float else i for i in rt_data[\"rt_m\"]]\n",
    "\n",
    "    rt_data['rt_clean'] = pd.to_numeric(rt_data['rt'], errors='coerce')\n",
    "    rt_data['rt_m'] = pd.to_numeric(rt_data['rt_m'], errors='coerce')\n",
    "    \n",
    "    acc_con = data[data[\"congruent\"] == 1][\"fl_accuracy\"]\n",
    "    acc_incon = data[data[\"congruent\"] == 0][\"fl_accuracy\"]\n",
    "\n",
    "    good_letters = ['B', 'b', 'D', 'd',\n",
    "    'F', 'f', 'G', 'g', 'H', 'h',\n",
    "    'J', 'j', 'K', 'k', #'L',\n",
    "    'M', 'm', 'N', 'n', 'P', 'p',\n",
    "    'Q', 'q', 'R', 'r',\n",
    "    'T', 't',]\n",
    "\n",
    "    good_rt_data = rt_data[rt_data['fl_stim'].str.contains('|'.join(good_letters))]\n",
    "    \n",
    "    flanker_data[\"sub\"].append(sub)\n",
    "    flanker_data[\"acc\"].append(acc_fl.mean())\n",
    "    flanker_data[\"acc_con\"].append(acc_con.mean())\n",
    "    flanker_data[\"acc_incon\"].append(acc_incon.mean())\n",
    "    flanker_data[\"rt\"].append(rt_data.rt_clean.mean())\n",
    "    flanker_data[\"rt_con_corr\"].append(rt_data[(rt_data[\"congruent\"]==1) & (rt_data[\"acc\"]==1)].rt_clean.mean())\n",
    "    flanker_data[\"rt_incon_corr\"].append(rt_data[(rt_data[\"congruent\"]==0) & (rt_data[\"acc\"]==1)].rt_clean.mean())\n",
    "    flanker_data[\"rt_con_incorr\"].append(rt_data[(rt_data[\"congruent\"]==1) & (rt_data[\"acc\"]==0)].rt_clean.mean())\n",
    "    flanker_data[\"rt_incon_incorr\"].append(rt_data[(rt_data[\"congruent\"]==0) & (rt_data[\"acc\"]==0)].rt_clean.mean())\n",
    "    flanker_data[\"good_rt_con_corr\"].append(good_rt_data[(good_rt_data[\"congruent\"]==1) & (good_rt_data[\"acc\"]==1)].rt_clean.mean())\n",
    "    flanker_data[\"good_rt_incon_corr\"].append(good_rt_data[(good_rt_data[\"congruent\"]==0) & (good_rt_data[\"acc\"]==1)].rt_clean.mean())\n",
    "    flanker_data[\"good_rt_con_incorr\"].append(good_rt_data[(good_rt_data[\"congruent\"]==1) & (good_rt_data[\"acc\"]==0)].rt_clean.mean())\n",
    "    flanker_data[\"good_rt_incon_incorr\"].append(good_rt_data[(good_rt_data[\"congruent\"]==0) & (good_rt_data[\"acc\"]==0)].rt_clean.mean())\n",
    "    flanker_data[\"hand\"].append(counterbalance)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7443f04e-9c3c-4ab9-8538-d7b117215e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa96ac8-cd61-45bf-9738-36f5ddc4119f",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_letters = ['B', 'b', 'D', 'd',\n",
    "'F', 'f', 'G', 'g', 'H', 'h',\n",
    "'J', 'j', 'K', 'k', #'L',\n",
    "'M', 'm', 'N', 'n', 'P', 'p',\n",
    "'Q', 'q', 'R', 'r',\n",
    "'T', 't',]\n",
    "subset_df = rt_data[rt_data['fl_stim'].str.contains('|'.join(good_letters))]\n",
    "subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d7d6fad95932e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T18:10:32.218058Z",
     "start_time": "2024-02-03T18:10:32.166484Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "flanker_data = pd.DataFrame(flanker_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a78033c66044111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T18:10:34.954458Z",
     "start_time": "2024-02-03T18:10:34.857020Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "flanker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7f82f6-06ed-4d9c-9f23-c7691e6ccad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flanker_data[flanker_data[\"hand\"]==\"L\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa464b325d10ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T17:49:18.941767Z",
     "start_time": "2024-02-03T17:49:18.910883Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "flanker_data.describe().iloc[1:, :].round(2).to_excel(\"/Users/fzaki001/Documents/DA/letter-flanker/{}\".format(\"decr.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4724f24170162",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf529bbddaf84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T04:55:49.702173Z",
     "start_time": "2024-02-03T04:55:49.698035Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a9887ffbaaaf5c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### RT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30cfed1bfbf03fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T04:55:51.131464Z",
     "start_time": "2024-02-03T04:55:51.053523Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/letter-flanker/\"\n",
    "pic_name = \"RT_LR.png\"\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=flanker_data[\\\n",
    "            ['rt_con_corr', 'rt_incon_corr', 'rt_con_incorr', 'rt_incon_incorr',]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"RT (ms)\")\n",
    "plt.ylim(250, 900)\n",
    "\n",
    "#plt.savefig(path+\"{}\".format(pic_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936aad2-7c38-485c-9cc2-337a4e0906a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = \"/Users/fzaki001/Documents/DA/letter-flanker/\"\n",
    "pic_name = \"good_RT_LR.png\"\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=flanker_data[\\\n",
    "            ['good_rt_con_corr', 'good_rt_incon_corr', 'good_rt_con_incorr', 'good_rt_incon_incorr',]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"RT (ms)\")\n",
    "plt.ylim(250, 900)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c464c13d-b0df-4002-8655-8355d45fff75",
   "metadata": {},
   "source": [
    "#### Counterbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d9ed554ef2d79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T04:55:52.284398Z",
     "start_time": "2024-02-03T04:55:52.199421Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hand = \"R\"\n",
    "pic_name = \"RT_{}.png\".format(hand)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=flanker_data[flanker_data[\"hand\"]==hand][\\\n",
    "            ['rt_con_corr', 'rt_incon_corr', 'rt_con_incorr', 'rt_incon_incorr',]\\\n",
    "            ], palette=[\"skyblue\", \"lightcoral\", \"dodgerblue\", \"crimson\"])\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"RT (ms)\")\n",
    "plt.ylim(250, 900)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2279bf62e0e873",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe0580b2953d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T17:57:03.577342Z",
     "start_time": "2024-02-03T17:57:03.481584Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pic_name = \"ACC_LR.png\"\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=flanker_data[['acc_con', 'acc_incon']], palette=[\"skyblue\", \"lightcoral\"])\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.65, 1.05)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded691d1-ebe1-4572-8886-cc764eb39229",
   "metadata": {},
   "source": [
    "#### Counterbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10730136af80449f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T17:57:21.711840Z",
     "start_time": "2024-02-03T17:57:21.612631Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hand = \"R\"\n",
    "pic_name = \"ACC_{}.png\".format(hand)\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(data=flanker_data[flanker_data[\"hand\"]==hand][['acc_con', 'acc_incon']], palette=[\"skyblue\", \"lightcoral\"])\n",
    "\n",
    "plt.xlabel(\"Trial type\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.65, 1.05)\n",
    "\n",
    "plt.savefig(path+\"{}\".format(pic_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f29a714fc2cb67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-03T04:32:43.196825Z",
     "start_time": "2024-02-03T04:32:43.180300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "flanker_data.to_csv(\"/Users/fzaki001/Documents/flanker_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb32e3-e853-49c9-9ffa-c890838981f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[255, 255, 0] == [255, 255, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b841340-608e-4ad7-8633-84e2b0312502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print([1 1 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f66e92b-647c-4551-904b-a2cc943598f3",
   "metadata": {},
   "source": [
    "# Number Flanker analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4385144-d4e1-440c-9308-f428f8b1c8ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
