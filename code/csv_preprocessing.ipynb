{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f123a781-7610-48ef-a6e7-47ad4e85d348",
   "metadata": {},
   "source": [
    "## PsychoPy output .csv preprocessing script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c435c9-8a3f-43b5-a095-16d5c06570ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1b352c-4109-4fb5-bbd6-f79b1d2b4307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_list(input_list, chunk_size):\n",
    "    \"\"\"Splits the list into chunks of specified size.\"\"\"\n",
    "    return [input_list[i:i + chunk_size] for i in range(0, len(input_list), chunk_size)]\n",
    "\n",
    "def accuracy_with_order(user_responses, correct_answers):\n",
    "    accuracies = []\n",
    "    for user_resp, correct_ans in zip(user_responses, correct_answers):\n",
    "        correct_count = sum(u == c for u, c in zip(user_resp, correct_ans))\n",
    "        accuracy = correct_count / len(correct_ans)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies\n",
    "\n",
    "def accuracy_without_order(user_responses, correct_answers):\n",
    "    accuracies = []\n",
    "    for user_resp, correct_ans in zip(user_responses, correct_answers):\n",
    "        correct_count = sum(user_resp.count(c) for c in set(correct_ans))\n",
    "        accuracy = correct_count / len(correct_ans)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies\n",
    "\n",
    "def convert_to_floats(str_list):\n",
    "    float_list = []\n",
    "    for s in str_list:\n",
    "        # Use ast.literal_eval to safely evaluate the string as a list\n",
    "        # Then convert each element in the resulting list to a float\n",
    "        floats = ast.literal_eval(s)\n",
    "        float_list.extend(floats if isinstance(floats, list) else [floats])\n",
    "    return float_list\n",
    "\n",
    "# Updated function that extracts only the first float from each string\n",
    "def convert_to_floats(str_list):\n",
    "    float_list = []\n",
    "    for s in str_list:\n",
    "        # Use ast.literal_eval to safely evaluate the string as a list\n",
    "        # Then convert each element in the resulting list to a float\n",
    "        floats = ast.literal_eval(s)\n",
    "        float_list.extend(floats if isinstance(floats, list) else [floats])\n",
    "    return float_list\n",
    "\n",
    "def convert_strings_to_float_lists(str_list):\n",
    "    float_lists = []\n",
    "    for s in str_list:\n",
    "        if s == \"None\": \n",
    "            float_lists.append(s)\n",
    "        else:\n",
    "        # Convert the string representation of list to actual list and then to floats\n",
    "            float_list = [float(x) for x in ast.literal_eval(s)]\n",
    "            float_lists.append(float_list)\n",
    "    return float_lists\n",
    "\n",
    "def chunk_list(lst, n):\n",
    "        chunked_list = []\n",
    "        for i in range(0, len(lst), n):\n",
    "            chunked_list.append(lst[i:i + n])\n",
    "        return chunked_list\n",
    "\n",
    "def has_common_letter(pair1, pair2):\n",
    "        return any(letter in pair2 for letter in pair1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed4aa4-b9fc-4d5d-82f3-ba028f5b9fdb",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a20a34-9385-4f7f-97a5-fec7f35fef92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None\n",
    "n_blocks = 12\n",
    "n_supertrials = 6\n",
    "n_flanker = 8\n",
    "subsets = []\n",
    "path = \"/Users/fzaki001/Documents/wme/data/\"\n",
    "subjects = sorted([i[8:10] for i in os.listdir(path) if i.endswith(\"csv\")])\n",
    "wme_dict = dict({\n",
    "    \"sub\": [],\n",
    "    \"acc_fl\": [],\n",
    "    \"acc_norder\": [],\n",
    "    \"4-1_fl_error_wm_acc_norder\": [],\n",
    "    \"5-1_fl_error_wm_acc_norder\": [],\n",
    "    \"4-0_fl_error_wm_acc_norder\": [],\n",
    "    \"5-0_fl_error_wm_acc_norder\": [],\n",
    "    \"4-many_fl_error_wm_acc_norder\": [],\n",
    "    \"5-many_fl_error_wm_acc_norder\": [],\n",
    "    \"4-acc_fl\": [],\n",
    "    \"5-acc_fl\": [],\n",
    "    \"4-acc_con\": [],\n",
    "    \"5-acc_con\": [],\n",
    "    \"4-acc_incon\": [],\n",
    "    \"5-acc_incon\": [],\n",
    "    \"1_fl_error_trials\": [],\n",
    "    \"4-rt_con_corr\": [],\n",
    "    \"5-rt_con_corr\": [],\n",
    "    \"4-rt_incon_corr\": [],\n",
    "    \"5-rt_incon_corr\": [],\n",
    "    \"4-rt_con_incorr\": [],\n",
    "    \"5-rt_con_incorr\": [],\n",
    "    \"4-rt_incon_incorr\": [],\n",
    "    \"5-rt_incon_incorr\": [],\n",
    "    #\"pes\": [],\n",
    "    \"4-acc_order\": [],\n",
    "    \"5-acc_order\": [],\n",
    "    \"4-acc_norder\": [],\n",
    "    \"5-acc_norder\": [],\n",
    "    \"wm_err0_fl_err0\": [],\n",
    "    \"wm_err0_fl_err1\": [],\n",
    "    \"wm_err1_fl_err0\": [],\n",
    "    \"wm_err1_fl_err1\": [],\n",
    "    \"chi2\": [],\n",
    "    \"diff_con\": [],\n",
    "    \"diff_incon\": [],\n",
    "    \"4-mean_letters_from_fl_err\": [],\n",
    "    \"5-mean_letters_from_fl_err\": [],\n",
    "    \"4-mean_letters_from_fl_corr\": [],\n",
    "    \"5-mean_letters_from_fl_corr\": [],\n",
    "    \"cnt_mean\": [],\n",
    "    \"cnt_n\": [],\n",
    "    \"hand\": [],\n",
    "    \"repeat\": [],\n",
    "    \"repeat_cnt\": [],\n",
    "    \"not_repeat_cnt\": [],\n",
    "    \"ratio_incon_correct\": [],\n",
    "    \"4-ratio_incon_correct\": [],\n",
    "    \"5-ratio_incon_correct\": [],\n",
    "    \"ratio_post_incon_correct\": [],\n",
    "    \"4-ratio_post_incon_correct\": [],\n",
    "    \"5-ratio_post_incon_correct\": [],\n",
    "    \"ratio_incon_error\": [],\n",
    "    \"4-ratio_incon_error\": [],\n",
    "    \"5-ratio_incon_error\": [],\n",
    "    \"ratio_post_incon_error\": [],\n",
    "    \"4-ratio_post_incon_error\": [],\n",
    "    \"5-ratio_post_incon_error\": [],\n",
    "})\n",
    "\n",
    "for sub in subjects:\n",
    "    data = pd.read_csv(\"{}sub-2800{}_wme-eeg_s1_r1_e1.csv\".format(path, sub))\n",
    "    counterbalance = (data[\"hand\"][0], data[\"repeat\"][0])\n",
    "    row_start = list(data[\"conditionText\"]).index(4)\n",
    "    first_five_columns = data.iloc[row_start:, :5]\n",
    "    columns_from_start = data.iloc[row_start:, list(data.columns).index(\"wm_ISI\"):list(data.columns).index(\"supertrial_blockAcc_wm\")+1]\n",
    "    data = pd.concat([first_five_columns, columns_from_start], axis=1)\n",
    "    print(\"Loading subject {}\".format(sub))\n",
    "    print(\"\")\n",
    "\n",
    "    shown_letters = data[\"shown_letters\"].dropna().reset_index(drop=True)\n",
    "    shown_letters = [i for i in shown_letters if len(i)>=4]\n",
    "    for i in range(len(shown_letters)-1):\n",
    "        if shown_letters[i][:4] == shown_letters[i+1][:4]:\n",
    "            shown_letters[i] = shown_letters[i]+\"*\"\n",
    "    shown_letters = [i for i in shown_letters if i[-1] != \"*\"]\n",
    "    assert len(shown_letters) == (n_blocks * n_supertrials), \"Check your data length!\"\n",
    "    \n",
    "    wm_response = data[\"wm_response\"].dropna().reset_index(drop=True)\n",
    "    assert len(wm_response) == (n_blocks * n_supertrials), \"Check your data length!\"\n",
    "    \n",
    "    acc_order = accuracy_with_order(wm_response, [i.upper() for i in shown_letters])\n",
    "    assert len(acc_order) == n_blocks * n_supertrials, \"Check your data length!\"\n",
    "    \n",
    "    acc_norder = accuracy_without_order(wm_response, [i.upper() for i in shown_letters])\n",
    "    assert len(acc_norder) == n_blocks * n_supertrials, \"Check your data length!\"\n",
    "    \n",
    "    acc_fl = data[\"fl_accuracy\"].dropna().reset_index(drop=True)\n",
    "    assert len(acc_fl) == (n_blocks * n_supertrials * n_flanker), \"Check your data length!\"\n",
    "\n",
    "    blockAcc_wm = data[\"supertrial_blockAcc_wm\"].dropna().reset_index(drop=True)\n",
    "    assert len(blockAcc_wm) == n_blocks, \"Check your data length!\"\n",
    "\n",
    "    fl_supertrial_acc = [np.mean(i) for i in chunk_list(list(acc_fl), 8)]\n",
    "    assert len(fl_supertrial_acc) == (n_blocks * n_supertrials), \"Check your data length!\"\n",
    "    \n",
    "    blockAcc_fl = [np.mean(i) for i in chunk_list(list(fl_supertrial_acc), 6)]\n",
    "    assert len(blockAcc_fl) == n_blocks, \"Check your data length!\"\n",
    "    \n",
    "    fl_stim = data[\"flanker_stim\"].dropna().reset_index(drop=True)\n",
    "    assert len(fl_stim) == (n_blocks * n_supertrials * n_flanker), \"Check your data length!\"\n",
    "\n",
    "    for i, key in enumerate(list(data[\"task_stim_keyResp.keys\"])):\n",
    "        if (pd.isnull(key) and pd.notnull(list(data[\"fl_accuracy\"])[i])) :\n",
    "            data[\"task_stim_keyResp.rt\"].iloc[i] = \"None\"      \n",
    "    \n",
    "    congruent = data[\"congruent\"].dropna().reset_index(drop=True)\n",
    "    assert len(congruent) == (n_blocks * n_supertrials * n_flanker), \"Check your data length!\"\n",
    "\n",
    "    #print(\"Accuracy check...\")\n",
    "    if np.mean(acc_norder) < 0.7 or np.mean(acc_fl) < 0.7:\n",
    "        print (\"Low accuracy!\")\n",
    "        print(\"WM accuracy: {}\\nFlanker accuracy: {}\".format(round(np.mean(acc_norder), 4), round(np.mean(acc_fl), 4)))\n",
    "    else:\n",
    "        print (\"All accuracies > 0.7\")\n",
    "        print(\"WM accuracy: {}\\nFlanker accuracy: {}\".format(round(np.mean(acc_norder), 4), round(np.mean(acc_fl), 4)))\n",
    "    print(\"\")\n",
    "\n",
    "    # rt_trial = data[\"task_stim_keyResp.rt\"].dropna().reset_index(drop=True)\n",
    "# rt_trial = [i.split(\",\")for i in list(rt_trial)]\n",
    "# rt_trial[0]\n",
    "    \n",
    "    wm_acc_data = pd.DataFrame({\n",
    "    \"acc_order\": acc_order,\n",
    "    \"acc_norder\": acc_norder,\n",
    "    \"acc_fl\": fl_supertrial_acc,\n",
    "    \"wm_load\": ([4]*n_supertrials + [5]*n_supertrials) * (int(n_blocks/2))\n",
    "    })\n",
    "\n",
    "    fl_error_wm_acc_norder_1_4 = wm_acc_data[(wm_acc_data[\"acc_fl\"] == 0.875) & (wm_acc_data[\"wm_load\"] == 4)].acc_norder.mean()\n",
    "    fl_error_wm_acc_norder_1_5 = wm_acc_data[(wm_acc_data[\"acc_fl\"] == 0.875) & (wm_acc_data[\"wm_load\"] == 5)].acc_norder.mean()\n",
    "    fl_error_wm_acc_norder_0_4 = wm_acc_data[(wm_acc_data[\"acc_fl\"] == 1) & (wm_acc_data[\"wm_load\"] == 4)].acc_norder.mean()\n",
    "    fl_error_wm_acc_norder_0_5 = wm_acc_data[(wm_acc_data[\"acc_fl\"] == 1) & (wm_acc_data[\"wm_load\"] == 5)].acc_norder.mean()\n",
    "    fl_error_wm_acc_norder_many_4 = wm_acc_data[(wm_acc_data[\"acc_fl\"] < 0.875) & (wm_acc_data[\"wm_load\"] == 4)].acc_norder.mean()\n",
    "    fl_error_wm_acc_norder_many_5 = wm_acc_data[(wm_acc_data[\"acc_fl\"] < 0.875) & (wm_acc_data[\"wm_load\"] == 5)].acc_norder.mean()\n",
    "    \n",
    "    acc_order_4 = wm_acc_data[wm_acc_data[\"wm_load\"] == 4].acc_order.mean()\n",
    "    acc_order_5 = wm_acc_data[wm_acc_data[\"wm_load\"] == 5].acc_order.mean()\n",
    "    acc_norder_4 = wm_acc_data[wm_acc_data[\"wm_load\"] == 4].acc_norder.mean()\n",
    "    acc_norder_5 = wm_acc_data[wm_acc_data[\"wm_load\"] == 5].acc_norder.mean()\n",
    "    \n",
    "    \n",
    "    rt_data = pd.DataFrame({\"wm_load\": ([4]*(n_flanker*n_supertrials) + [5]*(n_flanker*n_supertrials)) * (int(n_blocks/2)),\n",
    "        \"rt\": list(pd.concat([data[\"flanker_stim\"].dropna(), data[\"task_stim_keyResp.rt\"]], axis=1).dropna()[\"task_stim_keyResp.rt\"]),\n",
    "                            \"congruent\": congruent,\n",
    "                            \"acc\": acc_fl}\n",
    "                          )\n",
    "    \n",
    "    assert len(rt_data) == (n_blocks * n_supertrials * n_flanker), \"Check your data length!\"\n",
    "    \n",
    "    rt_data[\"rt\"] = convert_strings_to_float_lists(rt_data[\"rt\"])\n",
    "    rt_data[\"rt\"] = [\"N\" if i == \"None\" else i for i in rt_data[\"rt\"]]\n",
    "    \n",
    "    rt_data[\"rt_m\"] = [i[0] for i in rt_data[\"rt\"]]\n",
    "    rt_data[\"rt\"] = [i[0] if len(i) == 1 else \"M\" for i in rt_data[\"rt\"]]\n",
    "    \n",
    "    rt_data[\"rt\"] = [i * 1000 if type(i) == float else i for i in rt_data[\"rt\"]]\n",
    "    rt_data[\"rt_m\"] = [i * 1000 if type(i) == float else i for i in rt_data[\"rt_m\"]]\n",
    "    \n",
    "    rt_data['rt_clean'] = pd.to_numeric(rt_data['rt'], errors='coerce')\n",
    "    rt_data['rt_m'] = pd.to_numeric(rt_data['rt_m'], errors='coerce')\n",
    "    \n",
    "    assert len(rt_data) == (n_blocks * n_supertrials * n_flanker), \"Check your data length!\"\n",
    "    \n",
    "    mean_fl_acc_4 = round(rt_data[(rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 4)].acc.mean(), 2)\n",
    "    mean_fl_acc_5 = round(rt_data[(rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 5)].acc.mean(), 2)\n",
    "    acc_con_4 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 4)].acc.mean(), 2)\n",
    "    acc_con_5 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 5)].acc.mean(), 2)\n",
    "    acc_incon_4 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 4)].acc.mean(), 2)\n",
    "    acc_incon_5 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"wm_load\"] == 5)].acc.mean(), 2)\n",
    "    rt_con_corr_4 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 1) & (rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    rt_con_corr_5 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 1) & (rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "    rt_incon_corr_4 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 1) & (rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    rt_incon_corr_5 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 1) & (rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "    rt_con_incorr_4 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 0) & (rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    rt_con_incorr_5 = round(rt_data[(rt_data[\"congruent\"] == 1) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 0) & (rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "    rt_incon_incorr_4 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 0) & (rt_data[\"wm_load\"] == 4)].rt_m.mean(), 4)\n",
    "    rt_incon_incorr_5 = round(rt_data[(rt_data[\"congruent\"] == 0) & (rt_data[\"rt_m\"] > 150) & (rt_data[\"acc\"] == 0) & (rt_data[\"wm_load\"] == 5)].rt_m.mean(), 4)\n",
    "\n",
    "    # rt_data[\"pes\"] = np.nan\n",
    "    # rt_data[\"pea\"] = np.nan\n",
    "    # for i in range(len(rt_data)-1):\n",
    "    #     if rt_data[\"acc\"][i] < 1:\n",
    "    #         pes = rt_data[\"rt_clean\"][i+1] - rt_data[\"rt_clean\"][i]\n",
    "    #         rt_data[\"pes\"][i+1] = pes\n",
    "    # pes = rt_data[\"pes\"].mean()\n",
    "\n",
    "    #print(\"sub: {}\".format(sub))\n",
    "    # print(\"congruent RT: {} ms\".format(rt_con))\n",
    "    # print(\"congruent acc: {}\".format(acc_con))\n",
    "    # print(\"incongruent RT: {} ms\".format(rt_incon))\n",
    "    # print(\"incongruent acc: {}\".format(acc_incon))\n",
    "    print(\"\")\n",
    "    print(\"-----------\")\n",
    "\n",
    "    chi_data = pd.DataFrame({\n",
    "    \"wm_error\":[1 if i<1 else 0 for i in acc_order],\n",
    "    \"fl_error\":[1 if i<1 else 0 for i in fl_supertrial_acc]\n",
    "    })\n",
    "    chi2, p, dof, expected = stats.chi2_contingency(pd.crosstab(chi_data[\"wm_error\"], chi_data[\"fl_error\"]))\n",
    "    crosstab = pd.crosstab(chi_data[\"wm_error\"], chi_data[\"fl_error\"]).stack()\n",
    "    wm_err0_fl_err0 = crosstab[0,0] # wm-err 0 fl-err 0\n",
    "    wm_err0_fl_err1 = crosstab[0,1] # wm-err 0 fl-err 1\n",
    "    wm_err1_fl_err0 = crosstab[1,0] # wm-err 1 fl-err 0\n",
    "    wm_err1_fl_err1 = crosstab[1,1] # wm-err 1 fl-err 1\n",
    "\n",
    "    intersection = dict({\n",
    "    \"shown_letters\":[],\n",
    "    \"response\":[],\n",
    "    \"fl_middle\":[],\n",
    "    \"shown_x_flanker\":[],\n",
    "    \"response_x_flanker\":[],\n",
    "    \"difference\":[],\n",
    "    \"acc_order\":[],\n",
    "    \"acc_norder\":[],\n",
    "    \"acc_fl\":[],\n",
    "    \"congruent\":[],\n",
    "    \"acc\":[],\n",
    "    })\n",
    "    for i in range(n_supertrials * n_blocks):\n",
    "        fl_middle= \"\".join([fl[2] for fl in chunk_list(list(fl_stim), 8)[i]])\n",
    "        congr = [fl for fl in chunk_list(list(congruent), 8)[i]]\n",
    "        accuracy = [ac for ac in chunk_list(list(acc_fl), 8)[i]]\n",
    "        intersection[\"shown_letters\"].append(shown_letters[i])\n",
    "        intersection[\"response\"].append(wm_response[i])\n",
    "        intersection[\"fl_middle\"].append(fl_middle)\n",
    "        intersection[\"shown_x_flanker\"].append(set(shown_letters[i].upper()).intersection(fl_middle.upper()))\n",
    "        intersection[\"response_x_flanker\"].append(set(wm_response[i].upper()).intersection(fl_middle.upper()))\n",
    "        intersection[\"difference\"].append(\n",
    "            set(wm_response[i].upper()).intersection(fl_middle.upper()).\\\n",
    "            difference(set(shown_letters[i].upper()).intersection(fl_middle.upper()))\n",
    "        )\n",
    "        intersection[\"acc_order\"].append(acc_order[i])\n",
    "        intersection[\"acc_norder\"].append(acc_norder[i])\n",
    "        intersection[\"acc_fl\"].append(fl_supertrial_acc[i])\n",
    "        intersection[\"congruent\"].append(congr)\n",
    "        intersection[\"acc\"].append(accuracy)\n",
    "\n",
    "    intersec_data = pd.DataFrame(intersection)\n",
    "    intersec_data[\"wm_load\"] = ([4]*n_supertrials + [5]*n_supertrials) * (int(n_blocks/2))\n",
    "    intersec_data[\"diff_con\"] = np.nan\n",
    "    intersec_data[\"diff_incon\"] = np.nan\n",
    "    for i, diff in enumerate(intersec_data[\"difference\"]): #correct\n",
    "        con_ct = 0\n",
    "        incon_ct = 0\n",
    "        for letter in diff:\n",
    "            ind = intersec_data[\"fl_middle\"][i].upper().index(letter)\n",
    "            if (intersec_data[\"congruent\"][i][ind] == 1) and (intersec_data[\"acc\"][i][ind] == 1):\n",
    "                con_ct +=1\n",
    "            elif (intersec_data[\"congruent\"][i][ind] == 0) and (intersec_data[\"acc\"][i][ind] == 1):\n",
    "                incon_ct +=1\n",
    "        intersec_data[\"diff_con\"][i] = con_ct\n",
    "        intersec_data[\"diff_incon\"][i] = incon_ct\n",
    "\n",
    "    intersec_data[\"len_difference\"] = [len(i) for i in intersec_data[\"difference\"]]\n",
    "    intersec_data[\"1h_difference\"] = [1 if len(i)>0 else 0 for i in intersec_data[\"difference\"]]\n",
    "    mean_letters_from_fl_err_4 = intersec_data[(intersec_data[\"acc_fl\"] < 1) & (intersec_data[\"wm_load\"] == 4)].len_difference.mean()\n",
    "    mean_letters_from_fl_err_5 = intersec_data[(intersec_data[\"acc_fl\"] < 1) & (intersec_data[\"wm_load\"] == 5)].len_difference.mean()\n",
    "    mean_letters_from_fl_corr_4 = intersec_data[(intersec_data[\"acc_fl\"] == 1) & (intersec_data[\"wm_load\"] == 4)].len_difference.mean()\n",
    "    mean_letters_from_fl_corr_5 = intersec_data[(intersec_data[\"acc_fl\"] == 1) & (intersec_data[\"wm_load\"] == 5)].len_difference.mean()\n",
    "\n",
    "    intersec_subset = intersec_data[(intersec_data[\"difference\"] != set()) & (intersec_data[\"acc_fl\"] == 0.875)]\n",
    "    cnt = []\n",
    "    for i in range(len(intersec_subset)):\n",
    "        ind_err = intersec_subset.acc.reset_index(drop=True)[i].index(0)\n",
    "        inds_letter = [intersec_subset.fl_middle.reset_index(drop=True)[i].upper().index(letter) for letter in intersec_subset.difference.reset_index(drop=True)[i]]\n",
    "        if any([ind_err == il for il in inds_letter]):\n",
    "            cnt.append(1)\n",
    "        else:\n",
    "            cnt.append(0)\n",
    "    intersec_subset[\"cnt\"] = cnt\n",
    "    intersec_subset[\"cnt_n\"] = len(cnt)\n",
    "    cnt_mean = intersec_subset[\"cnt\"].mean()\n",
    "    subsets.append(intersec_subset)\n",
    "\n",
    "    #if np.mean(acc_norder) > 0.7 and np.mean(acc_fl) > 0.7:\n",
    "    wme_dict[\"sub\"].append(sub)\n",
    "    wme_dict[\"acc_fl\"].append(np.mean(acc_fl))\n",
    "    wme_dict[\"acc_norder\"].append(np.mean(acc_norder))\n",
    "    wme_dict[\"4-1_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_1_4)\n",
    "    wme_dict[\"5-1_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_1_5)\n",
    "    wme_dict[\"4-0_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_0_4)\n",
    "    wme_dict[\"5-0_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_0_5)\n",
    "    wme_dict[\"4-many_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_many_4)\n",
    "    wme_dict[\"5-many_fl_error_wm_acc_norder\"].append(fl_error_wm_acc_norder_many_5)\n",
    "    wme_dict[\"4-acc_con\"].append(acc_con_4)\n",
    "    wme_dict[\"5-acc_con\"].append(acc_con_5)\n",
    "    wme_dict[\"4-acc_incon\"].append(acc_incon_4)\n",
    "    wme_dict[\"5-acc_incon\"].append(acc_incon_5)\n",
    "    wme_dict[\"4-acc_fl\"].append(mean_fl_acc_4)\n",
    "    wme_dict[\"5-acc_fl\"].append(mean_fl_acc_5)\n",
    "    wme_dict[\"1_fl_error_trials\"].append(round(len(intersec_data[intersec_data[\"acc_fl\"]==0.875])/len(intersec_data[intersec_data[\"acc_fl\"]<1]), 2))\n",
    "    wme_dict[\"4-rt_con_corr\"].append(rt_con_corr_4)\n",
    "    wme_dict[\"5-rt_con_corr\"].append(rt_con_corr_5)\n",
    "    wme_dict[\"4-rt_incon_corr\"].append(rt_incon_corr_4)\n",
    "    wme_dict[\"5-rt_incon_corr\"].append(rt_incon_corr_5)\n",
    "    wme_dict[\"4-rt_con_incorr\"].append(rt_con_incorr_4)\n",
    "    wme_dict[\"5-rt_con_incorr\"].append(rt_con_incorr_5)\n",
    "    wme_dict[\"4-rt_incon_incorr\"].append(rt_incon_incorr_4)\n",
    "    wme_dict[\"5-rt_incon_incorr\"].append(rt_incon_incorr_5)\n",
    "    #wme_dict[\"pes\"].append(pes)\n",
    "    wme_dict[\"4-acc_order\"].append(acc_order_4)\n",
    "    wme_dict[\"5-acc_order\"].append(acc_order_5)\n",
    "    wme_dict[\"4-acc_norder\"].append(acc_norder_4)\n",
    "    wme_dict[\"5-acc_norder\"].append(acc_norder_5)\n",
    "    wme_dict[\"wm_err0_fl_err0\"].append(wm_err0_fl_err0)\n",
    "    wme_dict[\"wm_err0_fl_err1\"].append(wm_err0_fl_err1)\n",
    "    wme_dict[\"wm_err1_fl_err0\"].append(wm_err1_fl_err0)\n",
    "    wme_dict[\"wm_err1_fl_err1\"].append(wm_err1_fl_err1)\n",
    "    wme_dict[\"chi2\"].append(p)\n",
    "    wme_dict[\"diff_con\"].append(intersec_data[\"diff_con\"].mean())\n",
    "    wme_dict[\"diff_incon\"].append(intersec_data[\"diff_incon\"].mean())\n",
    "    wme_dict[\"4-mean_letters_from_fl_err\"].append(mean_letters_from_fl_err_4)\n",
    "    wme_dict[\"5-mean_letters_from_fl_err\"].append(mean_letters_from_fl_err_5)\n",
    "    wme_dict[\"4-mean_letters_from_fl_corr\"].append(mean_letters_from_fl_corr_4)\n",
    "    wme_dict[\"5-mean_letters_from_fl_corr\"].append(mean_letters_from_fl_corr_5)\n",
    "    wme_dict[\"cnt_mean\"].append(cnt_mean)\n",
    "    wme_dict[\"cnt_n\"].append(intersec_subset[\"cnt_n\"].mean())\n",
    "    wme_dict[\"hand\"].append(counterbalance[0])\n",
    "    wme_dict[\"repeat\"].append(counterbalance[1])\n",
    "\n",
    "    fl_trials = pd.DataFrame(\n",
    "        {\"target\": [i[2] for i in fl_stim],\n",
    "        \"congruent\": congruent,\n",
    "        \"acc\": acc_fl,\n",
    "        }\n",
    "    )\n",
    "    labels = []\n",
    "    for i in range(len(fl_trials)):\n",
    "        if fl_trials[\"congruent\"][i] == 0 and fl_trials[\"acc\"][i] == 0: # incon-error\n",
    "            labels.append(\"incon-error\")\n",
    "        elif fl_trials[\"congruent\"][i] == 0 and fl_trials[\"acc\"][i] == 1: # incon-correct\n",
    "            labels.append(\"incon-correct\")\n",
    "        else:\n",
    "            labels.append(\"NA\")\n",
    "    fl_trials[\"label\"] = labels\n",
    "    \n",
    "    post_labels = []\n",
    "    post_labels.append(\"NA\")\n",
    "    for i in range(1, len(fl_trials)):\n",
    "        if fl_trials[\"label\"][i-1] == \"incon-correct\":\n",
    "            post_labels.append(\"post incon-correct\")\n",
    "        elif fl_trials[\"label\"][i-1] == \"incon-error\":\n",
    "            post_labels.append(\"post incon-error\")\n",
    "        else:\n",
    "            post_labels.append(\"NA\")\n",
    "    fl_trials[\"post_label\"] = post_labels\n",
    "    fl_trials[\"target\"] = [i.upper() for i in fl_trials[\"target\"]]\n",
    "    \n",
    "    recalls = []\n",
    "    for i in wm_response:\n",
    "        recalls += [i] * 8\n",
    "    \n",
    "    fl_trials[\"recall\"] = recalls\n",
    "    fl_trials[\"load\"] = ([4]*n_flanker*n_supertrials + [5]*n_flanker*n_supertrials) * (int(n_blocks/2))\n",
    "    \n",
    "    appeared = []\n",
    "    for i in range(len(fl_trials)):\n",
    "        if fl_trials[\"target\"][i] in fl_trials[\"recall\"][i]:\n",
    "            appeared.append(True)\n",
    "        else:\n",
    "            appeared.append(False)\n",
    "\n",
    "    fl_trials[\"appeared\"] = appeared\n",
    "\n",
    "    ratio_incon_correct = len((fl_trials[(fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "\n",
    "    ratio_incon_correct_4 = len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "\n",
    "    ratio_incon_correct_5 = len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"label\"] == \"incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    \n",
    "    ratio_post_incon_correct = len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "\n",
    "    ratio_post_incon_correct_4 = len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "\n",
    "    ratio_post_incon_correct_5 = len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"post_label\"] == \"post incon-correct\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    \n",
    "    ratio_incon_error = len((fl_trials[(fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "\n",
    "    ratio_incon_error_4 = len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "\n",
    "    ratio_incon_error_5 = len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"label\"] == \"incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "    \n",
    "    ratio_post_incon_error = len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "\n",
    "    ratio_post_incon_error_4 = len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"load\"] == 4) & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "\n",
    "    ratio_post_incon_error_5 = len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == True)]))/\\\n",
    "    len((fl_trials[(fl_trials[\"load\"] == 5) & (fl_trials[\"post_label\"] == \"post incon-error\") & (fl_trials[\"appeared\"] == False)]))\n",
    "\n",
    "    wme_dict[\"ratio_incon_correct\"].append(ratio_incon_correct)\n",
    "    wme_dict[\"4-ratio_incon_correct\"].append(ratio_incon_correct_4)\n",
    "    wme_dict[\"5-ratio_incon_correct\"].append(ratio_incon_correct_5)\n",
    "    \n",
    "    wme_dict[\"ratio_post_incon_correct\"].append(ratio_post_incon_correct)\n",
    "    wme_dict[\"4-ratio_post_incon_correct\"].append(ratio_post_incon_correct_4)\n",
    "    wme_dict[\"5-ratio_post_incon_correct\"].append(ratio_post_incon_correct_5)\n",
    "\n",
    "    wme_dict[\"ratio_incon_error\"].append(ratio_incon_error)\n",
    "    wme_dict[\"4-ratio_incon_error\"].append(ratio_incon_error_4)\n",
    "    wme_dict[\"5-ratio_incon_error\"].append(ratio_incon_error_5)\n",
    "    \n",
    "    wme_dict[\"ratio_post_incon_error\"].append(ratio_post_incon_error)\n",
    "    wme_dict[\"4-ratio_post_incon_error\"].append(ratio_post_incon_error_4)\n",
    "    wme_dict[\"5-ratio_post_incon_error\"].append(ratio_post_incon_error_5)\n",
    "\n",
    "    big_list = [i[2].upper() for i in fl_stim]\n",
    "    chunk_size = 8\n",
    "    result = chunk_list(big_list, chunk_size)\n",
    "    result = [\"\".join(i) for i in result]\n",
    "    \n",
    "    list1 = [\"\".join(i) for i in result]\n",
    "    list2 = [i.upper() for i in shown_letters]\n",
    "    repeat_cnt = 0\n",
    "    not_repeat_cnt = 0\n",
    "    for string1, string2 in zip(list1, list2):\n",
    "        if has_common_letter(string1, string2):\n",
    "            repeat_cnt +=1\n",
    "        else:\n",
    "            not_repeat_cnt +=1\n",
    "\n",
    "    wme_dict[\"repeat_cnt\"].append(repeat_cnt)\n",
    "    wme_dict[\"not_repeat_cnt\"].append(not_repeat_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb338910-c582-4579-91bd-48cbd9c0b1a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wme_data = pd.DataFrame(wme_dict)\n",
    "wme_data = wme_data.round(2)\n",
    "wme_data = wme_data[(wme_data[\"acc_fl\"]>0.7) & (wme_data[\"4-acc_norder\"]>0.7)].reset_index(drop=True)\n",
    "wme_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
